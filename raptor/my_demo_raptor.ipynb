{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generated the tree in google colab notebooks due to crashes when building the tree in the local environment.\n",
    "\n",
    "The generated tree is on the demo directory. demo/my_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up RAPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krimssmirk/Desktop/rag-llm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-25 13:06:27,651 - Loading faiss with AVX2 support.\n",
      "2024-09-25 13:06:27,762 - Successfully loaded faiss with AVX2 support.\n",
      "2024-09-25 13:06:28,312 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT3TurboSummarizationModel object at 0x108a61950>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x12e5f1910>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-09-25 13:06:28,313 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT3TurboSummarizationModel object at 0x108a61950>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x12e5f1910>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2024-09-25 13:06:28,314 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x108a618d0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2024-09-25 13:06:28,315 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT3TurboSummarizationModel object at 0x108a61950>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x12e5f1910>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: OpenAI\n",
      "            Embedding Model: <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x108a618d0>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <raptor.QAModels.GPT3TurboQAModel object at 0x12fb9aa50>\n",
      "            Tree Builder Type: cluster\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from raptor import RetrievalAugmentation\n",
    "\n",
    "# Initialize with default configuration. For advanced configurations, check the documentation. [WIP]\n",
    "RA = RetrievalAugmentation(tree=\"demo/my_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 13:06:28,341 - Using collapsed_tree\n",
      "2024-09-25 13:06:29,202 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-25 13:06:31,633 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The requirements for Nikkeijin, who is a Philippine national with significant financial capability applying for a multiple-entry temporary visitor visa to Japan, include the following key documents:\n",
      "\n",
      "1. Income Certificate (Shotoku-shomeisho)\n",
      "2. Tax Certificate (Nozei-shomeisho) detailing total income\n",
      "3. Photocopy of the Final Tax Return Form (Kakutei-shinkokusyo)\n",
      "4. Bank Certificate\n",
      "\n",
      "Additionally, Nikkeijin may need to provide an Invitation Letter, Itinerary in Japan, and Residence Certificate (Jumin-hyo) of the inviter and guarantor if applicable. It is important to ensure that all required documents are submitted accurately and in accordance with the guidelines provided by the Japanese embassy or consulate.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the requirements for nikkeijin?\"\n",
    "answer = RA.answer_question(question=question)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It lists the requirements but its not perfect. The naive rag does not list the requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
